{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0eda40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# In a Jupyter notebook __file__ is not defined — use the current working directory instead\n",
    "data_dir = Path.cwd() / 'data' / 'processed'\n",
    "df = pd.read_csv(data_dir / 'GaN2024_enriched.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94ece35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert LightPollutionIndex to numeric (removes 'Out of Range' entries)\n",
    "df['LightPollutionIndex'] = pd.to_numeric(df['LightPollutionIndex'], errors='coerce')\n",
    "\n",
    "# Convert CloudCover to numeric\n",
    "df['CloudCover'] = pd.to_numeric(df['CloudCover'], errors='coerce')\n",
    "\n",
    "# Remove rows with NaN values in these columns\n",
    "df = df.dropna(subset=['LightPollutionIndex', 'CloudCover', 'Elevation(m)', 'LimitingMag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b366142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "X = df[['Elevation(m)', 'CloudCover', 'SQMReading', 'LightPollutionIndex']]\n",
    "y = df['LimitingMag']\n",
    "\n",
    "# First split: 80% train+val, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21d50dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing RandomForest...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "# RandomForest hyperparameter search\n",
    "rf_param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 15, 25, None],\n",
    "    'min_samples_split': [2, 10],\n",
    "}\n",
    "\n",
    "print(\"Optimizing RandomForest...\")\n",
    "rf_search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(n_jobs=-1),\n",
    "    param_distributions=rf_param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "rf_search.fit(X_train, y_train)\n",
    "rf_test_pred = rf_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36c77678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HYPERPARAMETER OPTIMIZATION RESULTS\n",
      "============================================================\n",
      "\n",
      "RandomForest Best Parameters:\n",
      "{'n_estimators': 200, 'min_samples_split': 10, 'max_depth': 15}\n",
      "Test R²: 0.5327\n"
     ]
    }
   ],
   "source": [
    "# Evaluate both models on validation set\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HYPERPARAMETER OPTIMIZATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nRandomForest Best Parameters:\")\n",
    "print(rf_search.best_params_)\n",
    "print(f\"Test R²: {r2_score(y_test, rf_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "617e6ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance (RandomForest):\n",
      "            Feature  Importance\n",
      "         SQMReading    0.524272\n",
      "       Elevation(m)    0.245879\n",
      "         CloudCover    0.131318\n",
      "LightPollutionIndex    0.098531\n"
     ]
    }
   ],
   "source": [
    "# RandomForest Feature Importance\n",
    "print(\"\\nFeature Importance (RandomForest):\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_search.best_estimator_.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52e75d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model saved to: c:\\Users\\tolar\\code\\AI-for-Star-viewing\\best_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the final optimized model and scaler\n",
    "model_path = Path.cwd() / 'best_model.joblib'\n",
    "\n",
    "joblib.dump(rf_search.best_estimator_, model_path)\n",
    "\n",
    "print(f\"✓ Model saved to: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skyline (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
